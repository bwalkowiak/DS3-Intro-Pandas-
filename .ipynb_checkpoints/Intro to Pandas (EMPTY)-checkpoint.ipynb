{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS3 Kaggle Workshop - Intro to Pandas\n",
    "\n",
    "Welcome to our Intro to Pandas Jupyter Notebook. With our interactive problems, we hope to guide you in your learning process. Here, you can practice useful pandas functions for DataFrame manipulation and analysis. Have fun!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset we will be using is called “Movies on Netflix, Prime Video, Hulu and Disney+” from Kaggle. Here is the link to the dataset: https://www.kaggle.com/ruchi798/movies-on-netflix-prime-video-hulu-and-disney. For easier access, we have downloaded it into the same repository as this Jupyter Notebook for you, and named it \"Movies.csv.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note.** The slideshow presentation will be published after the workshop. This will allow you to look back at the material covered and go over concepts that we were not able to get to during the timeframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's import pandas and numpy, crucial Python libraries for any Jupyter Notebook session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file \"Movies.csv\" contains data on movies available on various streaming services. Let's read it into Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note.** pd.read_ is the general method of loading data into a Pandas dataframe. Whether the file type is csv, excel, json, etc. \n",
    "\n",
    "For example:\n",
    "\n",
    "movies = pd.read_excel('Movies.xls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heads or Tails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feel free to play around with the integer n in df.head(n) or df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Data: DataFrame Stucture and Datatypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the structure of your DataFrame using *df.shape*. This is an easy method of quantifying your DataFrame.  DataFrames often contain various data types and it can be beneficial to understand just what type are contained within. Here, *df.dtypes* is especially helpful. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting a Column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many different ways to select a column. **METHOD 1** consists of passing the column name in quotes the brackets following the dataframe. \n",
    "\n",
    "The brackets are known as indexing operators in Python, meaning it allows you to quickly access certain parts of the given data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**METHOD 2** consists of passing the column name following the dataframe and a period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**METHOD 3** consists of passing the column name in quotes into the *get()* method.\n",
    "\n",
    "The get() method returns the value of the item passed into it, therefore passing a particular column name will return the values within the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note.** Methods 4 and 5 are not recommended unless you also need specific rows too. Right now, we are solely focusing on selecting a particular column. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**METHOD 4** consists of passing the index of the column name into the *iloc* method.\n",
    "\n",
    "**METHOD 5** consists of passing the column name into the *loc* method. \n",
    "\n",
    "Both methods take in specifications for the row(s), then column(s). This means that whatever is in front of the comma specifies the row(s) and whatever is behind the comma specifies the column(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What does the colon stand for?**\n",
    "\n",
    "The colon specifies which slice of the dataframe we want. Since it is used before the comma, it is specifying which row(s) to get. pandas will **generally** give back the rows between the start (inclusive) and end (exclusive). There are special cases with loc, which we will see in a bit.\n",
    "\n",
    "For example, the 0:5 slice will result in elements from indices 0 (inclusive) to 5 (exclusive).\n",
    "\n",
    "If there is no start or end specified, **ALL elements** from start to end (inclusive) are selected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting Multiple Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can pass in a list of columns into the indexing operators (or the outermost brackets).\n",
    "\n",
    "A list in Python is formatted as comma-seperated items inside opening and closing brackets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Structures: Series & Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might notice that the result looks different than when we selected just a single column. Now, it looks more like a table, as opposed to a list. This is because we encountered two different data structures -- series and dataframe.\n",
    "\n",
    "*Series*: a single list with indices; a one-dimensional labeled array\n",
    "\n",
    "*Dataframe*: a collection of more than one series; a two-dimensional labeled data structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting a Row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like selecting a column, there are multiple ways to select a row. **METHOD 1** and **METHOD 2** consist of passing the row index into either the loc or iloc method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loc vs iloc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*loc* → retrieves rows and columns based on a label (or labels) that is/are passed\n",
    "\n",
    "*iloc* → retrieves rows and columns based on an index (or indices)  that is/are passed\n",
    "\n",
    "**NOTE.** loc is different from normal Python slices because it includes both the start & stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**METHOD 3** consists of passing in the slice, but just within the indexing operators. This method is only recommended if you have multiple rows to select, as opposed to one.\n",
    "\n",
    "This method returns a dataframe as opposed to a series.\n",
    "\n",
    "0:1 slice means that we want items from index 0 to index 1 (exclusive), which is the same as asking for the item in index 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice Problem: iloc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the *iloc* method, how would you access the **year** Avengers: Infinity War was released (ie. third row, fourth column)?\n",
    "\n",
    "**NOTE.** Remember, indexing starts at 0, not 1. Also, iloc takes in **indices**, not strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting Multiple Rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**METHOD 1** for selecting multiple rows is exactly like METHOD 3 for selecting a row. The only difference is that the slice covers more ground! Similarly, it returns a dataframe.\n",
    "\n",
    "0:5 means that we want items from index 0 to index 5 (exclusive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#same as df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**METHOD 2** and **METHOD 3** consists of passing the row indices into the iloc or loc method.\n",
    "\n",
    "**NOTE.** loc is different from normal Python slices because it includes both the start & stop.\n",
    "\n",
    "0:5 for iloc and 0:4 for loc returns the same thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice Problem: Selecting Multiple Rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using .loc, return the *fifth to tenth (inclusive) rows* of the dataframe. Feel free to do all if time allows.\n",
    "\n",
    "**NOTE.** Think about how rows correspond with indices. What index is the first row, and so on?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- *Data Cleaning*: correcting/removing erroneous values, filling in missing values\n",
    "- Data Cleaning and Preparation take around 80% of a data scientist’s time.\n",
    "- Garbage in → Garbage out (GIGO): Your analysis can only be as good as the data going into it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning Part 1: Dropping Columns\n",
    "- Try to find find which columns are redundant or irrelevant to your analysis. \n",
    "- Notice that there are initially 17 columns and 16744 rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The 'Unnamed: 0', 'ID', and 'Type' columns do not seem to hold any valuable information, so we can drop them using **.drop()**!\n",
    "- Note the new dimensions! What changed?\n",
    "- Some parameters: \n",
    "  - 'axis' parameter: tells whether to drop rows or columns. The default for **.drop()** is 0, which drops rows. We must use axis = 1 since we want to drop columns.\n",
    "  - 'inPlace' parameter: tells whether to do an operation in place or to return a copy. Doing an operation in place (inPlace = True) changes the dataset, which you do not always want. However, since we want to permanently drop these columns, we will use inPlace = True here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning Part 2: Dealing with Null Values\n",
    "- Datasets are usually imperfect: they contain many NaN values, and it is our job as data scientists to fix that!\n",
    "- We will need to use the handy **.dropna()** function. \n",
    "- Let's first use the **.dropna()** function with no parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This line dropped every row that had at least 1 NaN value. Out of the 16744 total rows in the dataset, only 3301 rows had no missing values. \n",
    "- 13443 (16744 - 14) rows, around 80% of the dataset, were dropped in this line!\n",
    "- This is NOT a good example of data cleaning.\n",
    "- Good thing we kept the default inPlace = False :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A better approach is to use the parameters to specify what you want to drop.\n",
    "- 'how' Parameter: Dictates whether a row/column is dropped if ALL of its values are NaN or ANY of its values are NaN. The default is to drop a row/column if ANY are NaN.\n",
    "- As seen by the resulting dimensions in this following line of code, there were no rows with ALL NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Create a distribution of movies comparing the IMDb ratings of movies across the major streaming platforms. \n",
    "- We will be dropping rows (axis = 0 by default) in the 'IMDB' column. We use how = 'any' because we want any rows with empty values in our specified column to be purged. This does not make a difference in this example, but will in the following one!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping Rows in Multiple Columns:  Create a distribution of the average rating (mean of the IMDb and Rotten Tomatoes ratings) of Netflix movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning Part 3: Renaming Columns\n",
    "### Method 1: Use the method **.rename()**\n",
    "- Better option for changing only a few column names\n",
    "- Useful if you want to use a function on all column names, like str.lower.\n",
    "- Use inPlace = True if you want to permanently change the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2: Use the attribute **.columns**\n",
    "- Better for changing several columns names\n",
    "- Order is crucial!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning Part 4: Data Formatting\n",
    "- Data must be formatted in the correct way or your analysis may be filled with errors!\n",
    "- Let's take the example of the Rotten Tomatoes values. They are written like \"__%\", which is a String value.\n",
    "  - Intuitively speaking, 100 > 99. However, Strings compare each digit so ‘100%’ < ‘99%’\n",
    "  - If we look at the worst movies, or sort from lowest rating to highest, the movies with a Rotten Tomatoes of 100% would come first.\n",
    "  - If we look at the best movies, or sort from highest rating to lowest, the movies with a Rotten Tomatoes of 99% would come first.\n",
    "  - We must fix this if we want to sort by Rotten Tomatoes later!\n",
    "\n",
    "- Procedure: Convert every value in the column to a numeric value by stripping the ‘%’ and casting the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditionals\n",
    "- Great tool for filtering out your dataframe to include only pertinent information\n",
    "- Python comparison operators ( ==, !=, <, <=, >, >= ) for each comparison \n",
    "- Python bitwise operators ( & for AND, | for OR) to combine comparisons\n",
    "\n",
    "### Example: Filter out the movies dataset to include only the Disney+ movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boolean Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boolean Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- String Operations:\n",
    "  - Searching for a substring? Just use the Series function **.str.contains()**\n",
    "\n",
    "### Example: Find all the movies that were directed by Steven Spielberg and were Family movies or Action movies.\n",
    "- NOTE: we need to use .str.contains() in this case because a movie may have multiple directors or genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple Conditionals: Intermediary variables help you keep track of your steps!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Condensed into 1 line: Same result but faster to write and usually harder to debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice Problem: Conditionals\n",
    "You’re holding a club social virtually through Netflix Party next Friday. As all of your members are adults, you choose to watch a movie that is suitable for ‘16+’ or ‘18+’. (This dataset doesn’t do MPAA ratings like PG-13 or R). You also want to watch a Comedy movie that came out sometime between 2000 and 2016 (inclusive). Also, you don’t really have high expectations for this movie. Anything rated above a 5.5 on IMDb is perfect.\n",
    "\n",
    "Create a “social” dataframe that has all the possible movies according to your criteria!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another Practice Problem!\n",
    "You are babysitting your little sibling, who refuses to fall asleep until you watch a movie with him. You only have Netflix and Prime Video and want to watch critically-acclaimed movies (IMDb of at least 8). You would prefer movies that were released in 2000 or later. You must show a movie suitable for “all” ages unless you want to be grounded. Since you have homework to do, the movie should be 1 ½ hours, at the most.\n",
    "\n",
    "Create a “babysitting” dataframe that has all the possible movies according to your criteria!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting a Single Column\n",
    "- We can use the **.sort_values()** function!\n",
    "- 'ascending' Parameter: determines whether to sort the dataframe in ascending or descending order. The default is ascending = True.\n",
    "\n",
    "\n",
    "### Example: Let’s sort the movies according to Rotten Tomatoes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rotten Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Certified Fresh!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting Multiple Columns\n",
    "\n",
    "- Simply pass a list to the 'by' parameter!\n",
    "- Order in the list matters! Will sort according to the first column in the list, and in case of any ties, the second column in the list will take precedence.\n",
    "- Note how the difference in order makes a vast difference in the dataframe you get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What if we want to sort columns in different directions? (Ex: finding critically-acclaimed classics)\n",
    "- Pass a list to the 'ascending' parameter!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice Problem: Sorting\n",
    "\n",
    "There are still too many movies to choose from for your social. Since all 108 of the movies fit your criteria from before, you now decide to find the movies with the best Rotten Tomatoes ratings and IMDb ratings, in that order. \n",
    "\n",
    "Create a “social_sorted” dataframe that has the top movies from the “social” dataframe. Then use the previous strategies for indexing and slicing to find the top 10 movies which your club can vote on!\n",
    "\n",
    "Hint: The indices will not be in numerical order after you sort according to rating, so look for a method to reset the indices!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: First sort the values accordingly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Try slicing!\n",
    "# This will give you an error, so you can comment out this line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Reset the index for slicing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Now try slicing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Note the difference in indexing between loc[] and iloc[] in the previous example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting Data\n",
    "- You can export your Pandas dataframe after your analysis!\n",
    "- Several options: .to_csv(), .to_excel(), .to_html(), .to_json(), .to_string()\n",
    "  - Full list on the Pandas documentation!\n",
    "- Export location: your working directory\n",
    "- Scenario: Your officer team loves the data analysis you did to find a good movie! Let’s send our teammates a CSV file with the movies so they can make an easy decision next time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Exporting data with the index leaves an extra column when you open it in Excel or read it into a new dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thanks for joining us and good luck for all your endeavors in Data Science!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
